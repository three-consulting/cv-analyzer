{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Document Content Generation\n",
    "\n",
    "The task is to:\n",
    "\n",
    "- Pick randomly a job and a skill set related to the given job\n",
    "- Create prompt messages from the job and skill set\n",
    "- Give the prompt message to openai api\n",
    "- Map the openai api response into `pandas DataFrame`\n",
    "- Save the `DataFrame` into a `parquet` file and compres it into `gzip`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Openai api key\n",
    "\n",
    "Openai api key has to be saved in to your environment variables with key `OPENAI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jobs and skill sets\n",
    "\n",
    "We're going to have multiple jobs as data labels and skills related to each job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"skills.json\") as f:\n",
    "    skills = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = list(skills.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a prompt message\n",
    "\n",
    "The message is based on randomly selected experience, job and set of skills for the given job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message_and_job():\n",
    "    experience = random.randint(0, 40)\n",
    "    job = random.choice(jobs)\n",
    "\n",
    "    job_skills = skills[job]\n",
    "\n",
    "    stack = list(dict.fromkeys(random.choices(job_skills, k=random.randint(1, len(job_skills)))))\n",
    "\n",
    "    skill_stack = \", \".join(stack[0: len(stack) - 2]) + \" and \" + stack[len(stack) - 1] + \".\"\n",
    "    content = \"Create a resume for \" + job + \", with \" + str(experience) + \" of years experience of \" + skill_stack\n",
    "\n",
    "    return {\n",
    "        \"job\": job,\n",
    "        \"stack\": stack,\n",
    "        \"message\": [{ \"role\": \"user\", \"content\": content }],\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate resume documents\n",
    "\n",
    "### Generate resume content\n",
    "\n",
    "Resume document content is generated with openai api using `gpt-3.5-turbo` LLM (Large Language Model). ChatGPT was based on the same LLM. The output will be a dictionary consisting of the job with experience as label and resume content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_resume():\n",
    "    messages_and_job = create_message_and_job()\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages_and_job[\"message\"],\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"job\": messages_and_job[\"job\"],\n",
    "        \"stack\": messages_and_job[\"stack\"],\n",
    "        \"resume\": response[\"choices\"][0][\"message\"][\"content\"],\n",
    "    }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate multiple resumes\n",
    "\n",
    "This function uses previous `generate_resume` function and uses it given `k` times to create resume document content. Finally resumes will be added into a `pandas DataFrame` and returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_resumes(k):\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    resume_jobs = []\n",
    "    resume_skills = []\n",
    "    resumes = []\n",
    "\n",
    "\n",
    "\n",
    "    for i in tqdm(range(k)):\n",
    "        try:\n",
    "            resume = generate_resume()\n",
    "            resume_jobs.append(resume[\"job\"])\n",
    "            resume_skills.append(resume[\"stack\"])\n",
    "            resumes.append(resume[\"resume\"])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "\n",
    "    df[\"jobs\"] = resume_jobs\n",
    "    df[\"skills\"] = resume_skills\n",
    "    df[\"resumes\"] = resumes\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to generate 10 resumes into a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resumes = generate_resumes(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and save them into a `parquet` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path(\"../data/df.resumes.gzip\")\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = pd.read_parquet(filepath)\n",
    "\n",
    "if df_old.size > 0:\n",
    "    pd.concat([df_old, df_resumes]).drop_duplicates(subset=[\"resumes\"]).to_parquet(filepath, compression=\"gzip\")\n",
    "else:\n",
    "    df_resumes.to_parquet(filepath, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet(filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
